{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"LLM_PROVIDER\"] = \"google\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyB1EZnCPsTn6MaHSdo24tk1mRPGTTJM85g\"\n"
      ],
      "metadata": {
        "id": "tzKeiyghCrRA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nest_asyncio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqSyf9gVDYdO",
        "outputId": "e7768b8c-7f3a-46af-fbce-bcf6fa81f205"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.12/pathlib.py:404: RuntimeWarning: coroutine 'Server.serve' was never awaited\n",
            "  parsed = [sys.intern(str(x)) for x in rel.split(sep) if x and x != '.']\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECQSyk68-gtm",
        "outputId": "3931a9ac-7b39-415e-e4ec-c0dac7d188c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [1098]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Initializing Fynd AI Feedback System...\n",
            "âœ“ Database: reviews.db\n",
            "âœ“ LLM Provider: google\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Fynd AI Feedback System - Production Backend\n",
        "FastAPI + SQLite + Claude/Gemini Integration\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import sqlite3\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "from typing import List, Optional\n",
        "from contextlib import asynccontextmanager\n",
        "\n",
        "from fastapi import FastAPI, HTTPException, Query\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel, Field, field_validator\n",
        "import httpx\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Centralized configuration\"\"\"\n",
        "    DATABASE_PATH = \"reviews.db\"\n",
        "    LLM_PROVIDER = os.getenv(\"LLM_PROVIDER\", \"anthropic\")  # anthropic or google\n",
        "    ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
        "    GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
        "    MAX_REVIEW_LENGTH = 5000\n",
        "    LLM_TIMEOUT = 30\n",
        "    LLM_MAX_RETRIES = 2\n",
        "\n",
        "# ============================================================================\n",
        "# DATABASE LAYER\n",
        "# ============================================================================\n",
        "\n",
        "class DatabaseManager:\n",
        "    \"\"\"Handles all database operations with clean abstraction\"\"\"\n",
        "\n",
        "    def __init__(self, db_path: str):\n",
        "        self.db_path = db_path\n",
        "        self.init_database()\n",
        "\n",
        "    def get_connection(self):\n",
        "        \"\"\"Get database connection with row factory\"\"\"\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        conn.row_factory = sqlite3.Row\n",
        "        return conn\n",
        "\n",
        "    def init_database(self):\n",
        "        \"\"\"Initialize database schema\"\"\"\n",
        "        conn = self.get_connection()\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        cursor.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS reviews (\n",
        "                id TEXT PRIMARY KEY,\n",
        "                rating INTEGER NOT NULL,\n",
        "                review_text TEXT NOT NULL,\n",
        "                ai_response TEXT NOT NULL,\n",
        "                ai_summary TEXT NOT NULL,\n",
        "                ai_recommended_action TEXT NOT NULL,\n",
        "                created_at TEXT NOT NULL\n",
        "            )\n",
        "        \"\"\")\n",
        "\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "    def insert_review(\n",
        "        self,\n",
        "        rating: int,\n",
        "        review_text: str,\n",
        "        ai_response: str,\n",
        "        ai_summary: str,\n",
        "        ai_recommended_action: str\n",
        "    ) -> str:\n",
        "        \"\"\"Insert a new review and return its ID\"\"\"\n",
        "        conn = self.get_connection()\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        review_id = str(uuid.uuid4())\n",
        "        created_at = datetime.utcnow().isoformat()\n",
        "\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO reviews\n",
        "            (id, rating, review_text, ai_response, ai_summary, ai_recommended_action, created_at)\n",
        "            VALUES (?, ?, ?, ?, ?, ?, ?)\n",
        "        \"\"\", (review_id, rating, review_text, ai_response, ai_summary, ai_recommended_action, created_at))\n",
        "\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "        return review_id\n",
        "\n",
        "    def get_all_reviews(self, rating_filter: Optional[int] = None) -> List[dict]:\n",
        "        \"\"\"Retrieve all reviews with optional rating filter\"\"\"\n",
        "        conn = self.get_connection()\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        if rating_filter:\n",
        "            cursor.execute(\"\"\"\n",
        "                SELECT rating, review_text, ai_summary, ai_recommended_action, created_at\n",
        "                FROM reviews\n",
        "                WHERE rating = ?\n",
        "                ORDER BY created_at DESC\n",
        "            \"\"\", (rating_filter,))\n",
        "        else:\n",
        "            cursor.execute(\"\"\"\n",
        "                SELECT rating, review_text, ai_summary, ai_recommended_action, created_at\n",
        "                FROM reviews\n",
        "                ORDER BY created_at DESC\n",
        "            \"\"\")\n",
        "\n",
        "        rows = cursor.fetchall()\n",
        "        conn.close()\n",
        "\n",
        "        return [dict(row) for row in rows]\n",
        "\n",
        "# ============================================================================\n",
        "# LLM SERVICE LAYER\n",
        "# ============================================================================\n",
        "\n",
        "class LLMService:\n",
        "    \"\"\"Handles all LLM interactions with retry logic and fallbacks\"\"\"\n",
        "\n",
        "    def __init__(self, provider: str, api_key: Optional[str]):\n",
        "        self.provider = provider\n",
        "        self.api_key = api_key\n",
        "\n",
        "        if not api_key:\n",
        "            raise ValueError(f\"API key required for {provider}\")\n",
        "\n",
        "    async def generate_feedback(self, rating: int, review_text: str) -> dict:\n",
        "        \"\"\"\n",
        "        Generate AI feedback with retry logic\n",
        "        Returns: {ai_response, ai_summary, ai_recommended_action}\n",
        "        \"\"\"\n",
        "        for attempt in range(Config.LLM_MAX_RETRIES):\n",
        "            try:\n",
        "                if self.provider == \"anthropic\":\n",
        "                    return await self._call_anthropic(rating, review_text)\n",
        "                elif self.provider == \"google\":\n",
        "                    return await self._call_google(rating, review_text)\n",
        "                else:\n",
        "                    raise ValueError(f\"Unsupported provider: {self.provider}\")\n",
        "\n",
        "            except httpx.TimeoutException:\n",
        "                if attempt == Config.LLM_MAX_RETRIES - 1:\n",
        "                    return self._get_fallback_response(rating)\n",
        "                continue\n",
        "\n",
        "            except Exception as e:\n",
        "                if attempt == Config.LLM_MAX_RETRIES - 1:\n",
        "                    print(f\"LLM error after retries: {e}\")\n",
        "                    return self._get_fallback_response(rating)\n",
        "                continue\n",
        "\n",
        "        return self._get_fallback_response(rating)\n",
        "\n",
        "    async def _call_anthropic(self, rating: int, review_text: str) -> dict:\n",
        "        \"\"\"Call Anthropic Claude API\"\"\"\n",
        "        prompt = self._build_prompt(rating, review_text)\n",
        "\n",
        "        async with httpx.AsyncClient(timeout=Config.LLM_TIMEOUT) as client:\n",
        "            response = await client.post(\n",
        "                \"https://api.anthropic.com/v1/messages\",\n",
        "                headers={\n",
        "                    \"x-api-key\": self.api_key,\n",
        "                    \"anthropic-version\": \"2023-06-01\",\n",
        "                    \"content-type\": \"application/json\"\n",
        "                },\n",
        "                json={\n",
        "                    \"model\": \"claude-sonnet-4-20250514\",\n",
        "                    \"max_tokens\": 1000,\n",
        "                    \"messages\": [{\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": prompt\n",
        "                    }]\n",
        "                }\n",
        "            )\n",
        "\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "\n",
        "            # Extract text from response\n",
        "            content = data.get(\"content\", [])\n",
        "            if content and len(content) > 0:\n",
        "                llm_output = content[0].get(\"text\", \"\")\n",
        "                return self._parse_llm_output(llm_output)\n",
        "\n",
        "            raise ValueError(\"Empty response from Claude\")\n",
        "\n",
        "    async def _call_google(self, rating: int, review_text: str) -> dict:\n",
        "        \"\"\"Call Google Gemini API\"\"\"\n",
        "        prompt = self._build_prompt(rating, review_text)\n",
        "\n",
        "        async with httpx.AsyncClient(timeout=Config.LLM_TIMEOUT) as client:\n",
        "            response = await client.post(\n",
        "                f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key={self.api_key}\",\n",
        "                json={\n",
        "                    \"contents\": [{\n",
        "                        \"parts\": [{\"text\": prompt}]\n",
        "                    }]\n",
        "                }\n",
        "            )\n",
        "\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "\n",
        "            # Extract text from Gemini response\n",
        "            candidates = data.get(\"candidates\", [])\n",
        "            if candidates and len(candidates) > 0:\n",
        "                parts = candidates[0].get(\"content\", {}).get(\"parts\", [])\n",
        "                if parts:\n",
        "                    llm_output = parts[0].get(\"text\", \"\")\n",
        "                    return self._parse_llm_output(llm_output)\n",
        "\n",
        "            raise ValueError(\"Empty response from Gemini\")\n",
        "\n",
        "    def _build_prompt(self, rating: int, review_text: str) -> str:\n",
        "        \"\"\"Build structured prompt for LLM\"\"\"\n",
        "        return f\"\"\"You are an AI customer feedback analyst for an e-commerce platform.\n",
        "\n",
        "A customer has submitted the following review:\n",
        "- Rating: {rating}/5 stars\n",
        "- Review: {review_text}\n",
        "\n",
        "Generate a JSON response with exactly these three fields:\n",
        "\n",
        "1. \"user_response\": A warm, professional reply to the customer (2-3 sentences)\n",
        "2. \"admin_summary\": A concise summary for internal teams (1 sentence)\n",
        "3. \"recommended_action\": A clear next action for the business (e.g., \"Follow up within 24 hours\", \"No action required\", \"Escalate to product team\")\n",
        "\n",
        "CRITICAL: Respond ONLY with valid JSON. No markdown, no code blocks, no additional text.\n",
        "\n",
        "Example format:\n",
        "{{\n",
        "  \"user_response\": \"Thank you for your feedback...\",\n",
        "  \"admin_summary\": \"Customer experienced shipping delay\",\n",
        "  \"recommended_action\": \"Follow up within 24 hours\"\n",
        "}}\"\"\"\n",
        "\n",
        "    def _parse_llm_output(self, llm_output: str) -> dict:\n",
        "        \"\"\"Parse LLM output with fallback handling\"\"\"\n",
        "        try:\n",
        "            # Clean potential markdown artifacts\n",
        "            cleaned = llm_output.strip()\n",
        "            if cleaned.startswith(\"```\"):\n",
        "                lines = cleaned.split(\"\\n\")\n",
        "                cleaned = \"\\n\".join(lines[1:-1]) if len(lines) > 2 else cleaned\n",
        "\n",
        "            parsed = json.loads(cleaned)\n",
        "\n",
        "            return {\n",
        "                \"ai_response\": parsed.get(\"user_response\", \"\"),\n",
        "                \"ai_summary\": parsed.get(\"admin_summary\", \"\"),\n",
        "                \"ai_recommended_action\": parsed.get(\"recommended_action\", \"\")\n",
        "            }\n",
        "\n",
        "        except json.JSONDecodeError:\n",
        "            # Fallback: extract manually\n",
        "            return {\n",
        "                \"ai_response\": \"Thank you for your feedback. We appreciate you taking the time to share your experience.\",\n",
        "                \"ai_summary\": f\"Customer rating: {llm_output[:100]}\",\n",
        "                \"ai_recommended_action\": \"Review manually\"\n",
        "            }\n",
        "\n",
        "    def _get_fallback_response(self, rating: int) -> dict:\n",
        "        \"\"\"Generate fallback response when LLM fails\"\"\"\n",
        "        if rating <= 2:\n",
        "            return {\n",
        "                \"ai_response\": \"Thank you for your feedback. We take all concerns seriously and will investigate this matter promptly.\",\n",
        "                \"ai_summary\": \"Low rating received - requires immediate attention\",\n",
        "                \"ai_recommended_action\": \"Escalate to customer success team within 4 hours\"\n",
        "            }\n",
        "        elif rating == 3:\n",
        "            return {\n",
        "                \"ai_response\": \"Thank you for your feedback. We're always working to improve our service.\",\n",
        "                \"ai_summary\": \"Neutral feedback - monitor for patterns\",\n",
        "                \"ai_recommended_action\": \"Add to weekly review queue\"\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                \"ai_response\": \"Thank you for your positive feedback! We're delighted to hear about your experience.\",\n",
        "                \"ai_summary\": \"Positive customer feedback\",\n",
        "                \"ai_recommended_action\": \"No immediate action required\"\n",
        "            }\n",
        "\n",
        "# ============================================================================\n",
        "# PYDANTIC MODELS\n",
        "# ============================================================================\n",
        "\n",
        "class ReviewSubmission(BaseModel):\n",
        "    \"\"\"Request model for review submission\"\"\"\n",
        "    rating: int = Field(..., ge=1, le=5, description=\"Rating from 1 to 5\")\n",
        "    review_text: str = Field(..., min_length=1, max_length=5000, description=\"Review text\")\n",
        "\n",
        "    @field_validator(\"review_text\")\n",
        "    @classmethod\n",
        "    def validate_review_text(cls, v: str):\n",
        "        if not v.strip():\n",
        "            raise ValueError(\"Review text cannot be empty\")\n",
        "        return v.strip()\n",
        "\n",
        "\n",
        "class ReviewSubmissionResponse(BaseModel):\n",
        "    \"\"\"Response model for review submission\"\"\"\n",
        "    status: str\n",
        "    ai_response: str\n",
        "\n",
        "class ReviewRecord(BaseModel):\n",
        "    \"\"\"Model for individual review record\"\"\"\n",
        "    rating: int\n",
        "    review_text: str\n",
        "    ai_summary: str\n",
        "    ai_recommended_action: str\n",
        "    created_at: str\n",
        "\n",
        "class ReviewsResponse(BaseModel):\n",
        "    \"\"\"Response model for reviews list\"\"\"\n",
        "    reviews: List[ReviewRecord]\n",
        "\n",
        "class HealthResponse(BaseModel):\n",
        "    \"\"\"Health check response\"\"\"\n",
        "    status: str\n",
        "    timestamp: str\n",
        "\n",
        "# ============================================================================\n",
        "# FASTAPI APPLICATION\n",
        "# ============================================================================\n",
        "\n",
        "@asynccontextmanager\n",
        "async def lifespan(app: FastAPI):\n",
        "    \"\"\"Lifecycle management\"\"\"\n",
        "    # Startup\n",
        "    print(\"ðŸš€ Initializing Fynd AI Feedback System...\")\n",
        "    print(f\"âœ“ Database: {Config.DATABASE_PATH}\")\n",
        "    print(f\"âœ“ LLM Provider: {Config.LLM_PROVIDER}\")\n",
        "    yield\n",
        "    # Shutdown\n",
        "    print(\"Shutting down...\")\n",
        "\n",
        "app = FastAPI(\n",
        "    title=\"Fynd AI Feedback System\",\n",
        "    description=\"Production-grade AI-powered customer feedback system\",\n",
        "    version=\"1.0.0\",\n",
        "    lifespan=lifespan\n",
        ")\n",
        "\n",
        "# CORS configuration\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# Initialize services\n",
        "db_manager = DatabaseManager(Config.DATABASE_PATH)\n",
        "llm_service = LLMService(\n",
        "    provider=Config.LLM_PROVIDER,\n",
        "    api_key=Config.ANTHROPIC_API_KEY if Config.LLM_PROVIDER == \"anthropic\" else Config.GOOGLE_API_KEY\n",
        ")\n",
        "\n",
        "# ============================================================================\n",
        "# API ENDPOINTS\n",
        "# ============================================================================\n",
        "\n",
        "@app.post(\"/submit-review\", response_model=ReviewSubmissionResponse)\n",
        "async def submit_review(submission: ReviewSubmission):\n",
        "    \"\"\"\n",
        "    Submit a customer review and receive AI-generated feedback\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Truncate if too long\n",
        "        review_text = submission.review_text\n",
        "        if len(review_text) > Config.MAX_REVIEW_LENGTH:\n",
        "            review_text = review_text[:Config.MAX_REVIEW_LENGTH]\n",
        "\n",
        "        # Generate AI feedback\n",
        "        feedback = await llm_service.generate_feedback(\n",
        "            rating=submission.rating,\n",
        "            review_text=review_text\n",
        "        )\n",
        "\n",
        "        # Store in database\n",
        "        db_manager.insert_review(\n",
        "            rating=submission.rating,\n",
        "            review_text=review_text,\n",
        "            ai_response=feedback[\"ai_response\"],\n",
        "            ai_summary=feedback[\"ai_summary\"],\n",
        "            ai_recommended_action=feedback[\"ai_recommended_action\"]\n",
        "        )\n",
        "\n",
        "        return ReviewSubmissionResponse(\n",
        "            status=\"success\",\n",
        "            ai_response=feedback[\"ai_response\"]\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing review: {e}\")\n",
        "        raise HTTPException(\n",
        "            status_code=500,\n",
        "            detail=\"Failed to process review. Please try again.\"\n",
        "        )\n",
        "\n",
        "@app.get(\"/get-reviews\", response_model=ReviewsResponse)\n",
        "async def get_reviews(rating: Optional[int] = Query(None, ge=1, le=5)):\n",
        "    \"\"\"\n",
        "    Retrieve all reviews with optional rating filter\n",
        "    \"\"\"\n",
        "    try:\n",
        "        reviews = db_manager.get_all_reviews(rating_filter=rating)\n",
        "        return ReviewsResponse(reviews=reviews)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving reviews: {e}\")\n",
        "        raise HTTPException(\n",
        "            status_code=500,\n",
        "            detail=\"Failed to retrieve reviews\"\n",
        "        )\n",
        "\n",
        "@app.get(\"/health\", response_model=HealthResponse)\n",
        "async def health_check():\n",
        "    \"\"\"\n",
        "    Health check endpoint\n",
        "    \"\"\"\n",
        "    return HealthResponse(\n",
        "        status=\"healthy\",\n",
        "        timestamp=datetime.utcnow().isoformat()\n",
        "    )\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN ENTRY POINT\n",
        "# ============================================================================\n",
        "\n",
        "import asyncio\n",
        "import uvicorn\n",
        "\n",
        "config = uvicorn.Config(\n",
        "    app,\n",
        "    host=\"0.0.0.0\",\n",
        "    port=8000,\n",
        "    log_level=\"info\",\n",
        ")\n",
        "\n",
        "server = uvicorn.Server(config)\n",
        "\n",
        "await server.serve()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IPsC0k95EcTs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}